{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 500px Machine Learning Engineer Intern - Tech Challenge\n",
    "## Fooling an MNIST Classifier with Adversarial Images, using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "Create adversarial images to fool a MNIST classifier in TensorFlow.\n",
    "\n",
    "Deep convolutional neural networks (CNN) are state of the art models for image classification and object detection. Such models play crucial role at 500px where we use them for many applications like automatic keywording, people detection and image search. It’s important to understand how they work and what their limitations are.\n",
    "One known “limitation” of CNN is that they can be fooled to misclassify an image with high confidence by slightly\n",
    "perturbing the pixels. \n",
    "\n",
    "This is illustrated on the image below:\n",
    "\n",
    "![](https://lh4.googleusercontent.com/Bz7CFzzMBRkKJ4xGqMTpufuL35Lf69z3DEoDAV-ZzD1OC9lMHYL4co0ED-LF2URMowvbDdqkRg6oxZHWeIspOVDkeaB0rqAfNpRHXfrhxS45U2cqsuX52J2GZwlFOB0TSc_rYxu7)\n",
    "\n",
    "The delta between the original image and the adversarial one is so small that it is impossible for humans to detect. The fun fact is other machine learning models like SVM and logistic regression can be tricked in the similar manner.\n",
    "\n",
    "Note that the “fast gradient sign” method presented in the [original paper by Goodfellow](https://arxiv.org/abs/1412.6572) produces adversarial images for a random target class. In this challenge we would like to generate adversarial images to misclassify any examples of ‘2’ as ‘6’ specifically. This puts certain implications on the final solution.\n",
    "\n",
    "One of the useful application for adversarial images is that if you train your deep CNN classifier on them you can improve its accuracy on non-adversarial examples.\n",
    "\n",
    "In this challenge you are given an opportunity to learn how to generate adversarial examples and also gain practical experience using Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Getting Started\n",
    "\n",
    "Let's start by importing dependencies, and loading up the MNIST dataset. Note that much of the code in this section, and sections to come, is repurposed from [this tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/#deep-mnist-for-experts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x11a7cb850>> ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cPickle as pickle \n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Neural Network \n",
    "\n",
    "Now that we have the data, let's get our feet wet with TensorFlow by implementing a basic fully connected neural network with one hidden layer, and see how it performs on the data. Note that aside from using the TensorFlow code mentioned earlier, much of this code is repurposed from an earlier project I've completed, which can be found [here](https://github.com/MunirAD/Facial_Recognition_AlexNet/blob/master/part2.py) (in the `fully_connected` function code).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914\n"
     ]
    }
   ],
   "source": [
    "def FullyConnectedNet(num_in, num_hid, num_out, lam, learn_rate, num_epochs, batch_size):\n",
    "    \n",
    "    # Set up a placeholder for the input 'x' and its label 'y_' \n",
    "    # Note the label is in one-of-k (one-hot) encoding\n",
    "    x = tf.placeholder(tf.float32, [None, num_in])\n",
    "    y_ = tf.placeholder(tf.float32, [None, num_out])\n",
    "\n",
    "    # Set up variables for the network parameters. Note this is a single-hidden\n",
    "    # layer network\n",
    "    W0 = tf.Variable(tf.random_normal([num_in, num_hid], stddev=0.01))\n",
    "    b0 = tf.Variable(tf.random_normal([num_hid], stddev=0.01))\n",
    "    W1 = tf.Variable(tf.random_normal([num_hid, num_out], stddev=0.01))\n",
    "    b1 = tf.Variable(tf.random_normal([num_out], stddev=0.01))\n",
    "    \n",
    "    # Initialize the variables\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    # Set up the computation of a forward pass on an input to the net\n",
    "    layer1 = tf.nn.relu(tf.matmul(x, W0) + b0)\n",
    "    layer2 = tf.matmul(layer1, W1) + b1\n",
    "    y = tf.nn.softmax(layer2)\n",
    "    \n",
    "    # Set up a decay penalty to regularize, reducing the risk of over-fitting\n",
    "    decay_penalty = lam*tf.reduce_sum(tf.square(W0)) + lam*tf.reduce_sum(tf.square(W1))\n",
    "    NLL = -tf.reduce_sum(y_*tf.log(y)) + decay_penalty\n",
    "    \n",
    "    # Set up the Gradient Descent optimization step on the objective function \n",
    "    # with the given learning rate\n",
    "    train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(NLL)\n",
    "    \n",
    "    # Set up the logic for what a correct prediction is, and \n",
    "    # classification accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # Do mini batch gradient descent\n",
    "    for i in range(num_epochs):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        train_step.run(feed_dict = {x: batch[0], y_ : batch[1]})\n",
    "    \n",
    "    # Print the accuracy on the validation data\n",
    "    print(accuracy.eval(feed_dict={x: mnist.validation.images, y_: mnist.validation.labels}))\n",
    "\n",
    "FullyConnectedNet(784, 300, 10, 0.01, 0.0005, 1000, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the validation set with the given hyperparameters for the above model, is approximately 91%. Now we can move on to a more interesting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, since the target for this project isn't to play around with Convolutional network architectures, let's stick with the architecture specified in the [TensorFlow tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/#deep-mnist-for-experts).\n",
    "\n",
    "The architecture specified by the tutorial is \n",
    "\n",
    "1) **CONV LAYER 1** \n",
    "\n",
    "Convolve on the input with 32 weight matrices, each in $\\mathbb{R}^{5\\times5}$. This results in an output volume with depth 32, the width and height of the output volume is $p$ where $p = \\frac{N-F}{S} + 1$, where $N$ is the width (& height) of the input image, $F$ is the width (& height) of the weights matrix, $S$ is the stride with which we convolve (how much we slide along the input image with each dot product). \n",
    "\n",
    "We know that $N$ is 28 (since we know that the MNIST images are in $\\mathbb{R}^{28\\times28}$), but it's mentioned in the tutorial that, for this architecture, we want the output of the conv layer to have the same dimensionality as the input in terms of width and length (so as not to lose information early in the model), this is achieved by padding it with 0's. To preserve the input spatially, the amount of zero-padding has to be $\\frac{F-1}{2}$, since $F = 5$, then we have to add 2 extra rows of zero's, and 2 extra columns of 0's, making $N = 32$. With that, and the fact that, $F = 5$, $S = 1$, the output volume is in $\\mathbb{R}^{28\\times28\\times32}$\n",
    "\n",
    "2) **MAX POOLING 1** \n",
    "\n",
    "Max pool on the output volume of the first conv layer, over $2\\times2$ blocks\n",
    "\n",
    "3) **CONV LAYER 2**\n",
    "\n",
    "WLOG, this conv layer functions in the same way as the first one, except that its input is the output of the first max pooling layer, and here we have 64 weights matrices (instead of 32)\n",
    "\n",
    "4) **MAX POOLING 2**\n",
    "\n",
    "WLOG, this pooling layer in the exact same way as the first pooling layer, except that its input is the output of the second conv layer.\n",
    "\n",
    "5) **Fully Connected Network**\n",
    "\n",
    "The output of the second max pooling layer can be thought of a highly-level feature map representing the input image, we need a fully connected network to take as input this feature map, and predict the class. The width and height of the feature map is in $\\mathbb{R}^{7\\times7}$ (as a result of the maxpooling) with depth (as a result of the second convolutional layer), thus the input to the fully connected network is in $\\mathbb{R}^{7\\times7\\times64}$. \n",
    "\n",
    "To feed it to a fully connected net, we flatten it to $\\mathbb{R}^{3136}$. There's one hidden layer with 784 units (note that in the tutorial, its actually 1024 units, I've changed it), and each hidden unit has its own bias term. So the parameters are $\\textbf{W}_0 \\in \\mathbb{R}^{3136\\times784}$ and $\\vec{b_0} \\in \\mathbb{R}^{784}$. A ReLU activation is applied at this layer, therefore the values of the hidden neurons are given by \n",
    "$$\\vec{h} = ReLU(\\textbf{W}_0^{\\text{T}}\\vec{x} + \\vec{b})$$\n",
    "Where $\\vec{x}$ is the flattened output of the second max pooling layer.\n",
    "\n",
    "The architecture specified in the tutorial uses [dropout](https://www.youtube.com/watch?v=kAwF--GJ-ek&spfreload=10) at this point to minimize overfitting. I will use the same thing.\n",
    "\n",
    "Then we go to the output layer, which has 10 output units (1 for each class), therefore our parameters are $\\textbf{W}_1 \\in \\mathbb{R}^{784\\times10}$ and $\\vec{b} \\in \\mathbb{R}^{10}$, so we get that the values of the output neurons are given by \n",
    "$$\\vec{o} = \\textbf{W}_1^{\\text{T}}\\vec{h} + \\vec{b_1}$$\n",
    "\n",
    "Finally, softmax is applied to $\\vec{o}$:\n",
    "$$\\forall i \\in enumerate(\\vec{o}), o[i] = \\frac{\\exp({{\\vec{o}[i]}})}{\\sum_{j \\in o}\\exp({\\vec{o}[j]})}$$\n",
    "\n",
    "Which gives us, \n",
    "$$P(y^{(k)} = i | \\textbf{x}^{(k)}) = \\vec{o}[i]$$\n",
    "\n",
    "Now that we're familiar with the architecture, let's copy the code (verbatim - with some comments added to know what's happening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1*: Two helper functions are defined to generate tensorFlow weight and bias variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2*: Two helper functions are defined to do the convolution operation and the pooling operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3*: Set up the pre fully connected net computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up placeholders for x and y_\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# Shape the image so that it matches with the parameters\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "# Set up the parameters & computation for the first convolutional + pooling layers\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Set up the parameters & computation for the second convolutional + pooling layers\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 4*: Set up the fully connected net computations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the computation & parameters for the hidden layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 784])\n",
    "b_fc1 = bias_variable([784])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Do dropout on the hidden layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Set up the computation & parameters for the output layer\n",
    "W_fc2 = weight_variable([784, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 5*: Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.72\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.88\n",
      "step 400, training accuracy 0.96\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 0.92\n",
      "step 700, training accuracy 0.96\n",
      "step 800, training accuracy 0.96\n",
      "step 900, training accuracy 0.96\n",
      "test accuracy 0.9625\n"
     ]
    }
   ],
   "source": [
    "# Set up the loss function we're minimizing\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "\n",
    "# Set up the optimizer method, note that the Adam update rule is being used instead of\n",
    "# basic Gradient Descent\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# Set up the rules for correct prediction and classifiaction accuracy, \n",
    "# and initialize the session variables\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# Do mini-batch gradient descent with stdout updates every \n",
    "# 100 epochs\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The conv net at this point is trained, (note that in the tutorial it was trained with 20,000 epochs, I only trained it for 1000 due to time constraints). Let's set up a function to do a forward pass on an input image and predict its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_predict(inp):\n",
    "    # Load the pre-trained model data\n",
    "    with open('model2_784hidden.pkl', 'r') as fp:\n",
    "        model = pickle.load(fp)\n",
    "    \n",
    "    # Fix the input shape to match the net input\n",
    "    shaped_input = np.reshape(inp,(1, 784))    \n",
    "    \n",
    "    # Set up placeholder for x\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "        \n",
    "    # Shape the image so that it matches with the parameters\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "    # Load up the parameters & set up computation for the first convolutional + pooling layers\n",
    "    W_conv1 = model['W_conv1']\n",
    "    b_conv1 = model['b_conv1']\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    # Load up the parameters & set up computation for the second convolutional + pooling layers\n",
    "    W_conv2 = model['W_conv2']\n",
    "    b_conv2 = model['b_conv2']\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    # Load up the parameters & set up computation for the hidden layer of the fully connected ned\n",
    "    W_fc1 = model['W_fc1']\n",
    "    b_fc1 = model['b_fc1']\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # Do dropout on the hidden layer\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # Load up the parameters & set up computation for the output layer\n",
    "    W_fc2 = model['W_fc2']\n",
    "    b_fc2 = model['b_fc2']\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    y = tf.nn.softmax(y_conv)\n",
    "    \n",
    "    # Initialize all the all the variables and run the session\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Get the softmax probability vector and return its argmax\n",
    "    prob = sess.run(y, feed_dict={x: shaped_input, keep_prob: 1.0})\n",
    "    return np.argmax(prob)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with adversarial images \n",
    "So far, we have a trained and ready to go fully-connected network, and a convolutional network. But we haven't generated any adversarial examples or gained any intuition as to how it works. Before diving into generating adversarial examples with the convolutional network, let's set up an extremely simple network, generate adversarial examples with it, and try to gain some intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BasicNet will just be 784 input units that connect directly to 10 output units, where softmax is applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0958\n"
     ]
    }
   ],
   "source": [
    "def BasicNet():\n",
    "    model = {}\n",
    "\n",
    "    # Set up placeholders for x and y_\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "    # Shape the image so that it matches with the parameters\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "    # Set up the parameters & computation for the first convolutional + pooling layers\n",
    "    W = tf.Variable(tf.random_normal([784, 10], stddev=0.01))\n",
    "    b = tf.Variable(tf.random_normal([10], stddev=0.01))\n",
    "    o = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "    y = tf.nn.softmax(o)\n",
    "\n",
    "    # Set up the loss function we're minimizing\n",
    "    NLL = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "    # Set up the optimizer method, note that the Adam update rule is being used instead of\n",
    "    # basic Gradient Descent\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.00001).minimize(NLL)\n",
    "\n",
    "    # Set up the logic for what a correct prediction is, and\n",
    "    # classification accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # Initialize the session variables\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # Do mini batch gradient descent\n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        train_step.run(feed_dict = {x: batch[0], y_ : batch[1]})\n",
    "\n",
    "    # Print the accuracy on the validation data\n",
    "    print(accuracy.eval(feed_dict={x: mnist.validation.images, y_: mnist.validation.labels}))\n",
    "    model['W'] = sess.run(W)\n",
    "    model['b'] = sess.run(b)\n",
    "\n",
    "BasicNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
